{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anishpalakurthi/Library/Python/3.10/lib/python/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "from top2vec import Top2Vec\n",
    "import json\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file_as_string(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            file_contents = file.read()\n",
    "        return file_contents\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def read_all_text_files_in_directory(directory_path):\n",
    "    text_files_list = []\n",
    "    # Use glob to get all files with a .txt extension in the directory\n",
    "    text_files = glob.glob(os.path.join(directory_path, '*.txt'))\n",
    "\n",
    "    for file_path in text_files:\n",
    "        file_contents = read_text_file_as_string(file_path)\n",
    "        if file_contents:\n",
    "            text_files_list.append(file_contents)\n",
    "\n",
    "    return text_files_list\n",
    "\n",
    "\n",
    "files = read_all_text_files_in_directory(\"data/songlyrics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 12:30:35,022 - top2vec - INFO - Pre-processing documents for training\n",
      "2023-07-30 12:30:36,162 - top2vec - INFO - Creating joint document/word embedding\n",
      "2023-07-30 12:31:20,469 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "2023-07-30 12:31:23,134 - top2vec - INFO - Finding dense areas of documents\n",
      "2023-07-30 12:31:23,136 - top2vec - INFO - Finding topics\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m Top2Vec(documents \u001b[39m=\u001b[39;49m files, speed \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mlearn\u001b[39;49m\u001b[39m\"\u001b[39;49m, workers \u001b[39m=\u001b[39;49m \u001b[39m4\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/top2vec/Top2Vec.py:666\u001b[0m, in \u001b[0;36mTop2Vec.__init__\u001b[0;34m(self, documents, min_count, topic_merge_delta, ngram_vocab, ngram_vocab_args, embedding_model, embedding_model_path, embedding_batch_size, split_documents, document_chunker, chunk_length, max_num_chunks, chunk_overlap_ratio, chunk_len_coverage_ratio, sentencizer, speed, use_corpus_file, document_ids, keep_documents, workers, tokenizer, use_embedding_model_tokenizer, umap_args, hdbscan_args, verbose)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    664\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00membedding_model\u001b[39m}\u001b[39;00m\u001b[39m is an invalid embedding model.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 666\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_topics(umap_args\u001b[39m=\u001b[39;49mumap_args, hdbscan_args\u001b[39m=\u001b[39;49mhdbscan_args, topic_merge_delta\u001b[39m=\u001b[39;49mtopic_merge_delta)\n\u001b[1;32m    668\u001b[0m \u001b[39m# initialize document indexing variables\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocument_index \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/top2vec/Top2Vec.py:1272\u001b[0m, in \u001b[0;36mTop2Vec.compute_topics\u001b[0;34m(self, umap_args, hdbscan_args, topic_merge_delta)\u001b[0m\n\u001b[1;32m   1269\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mFinding topics\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1271\u001b[0m \u001b[39m# create topic vectors\u001b[39;00m\n\u001b[0;32m-> 1272\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_topic_vectors(cluster\u001b[39m.\u001b[39;49mlabels_)\n\u001b[1;32m   1274\u001b[0m \u001b[39m# deduplicate topics\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deduplicate_topics(topic_merge_delta)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/top2vec/Top2Vec.py:816\u001b[0m, in \u001b[0;36mTop2Vec._create_topic_vectors\u001b[0;34m(self, cluster_labels)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39min\u001b[39;00m unique_labels:\n\u001b[1;32m    814\u001b[0m     unique_labels\u001b[39m.\u001b[39mremove(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtopic_vectors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_l2_normalize(\n\u001b[0;32m--> 816\u001b[0m     np\u001b[39m.\u001b[39;49mvstack([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdocument_vectors[np\u001b[39m.\u001b[39;49mwhere(cluster_labels \u001b[39m==\u001b[39;49m label)[\u001b[39m0\u001b[39;49m]]\n\u001b[1;32m    817\u001b[0m               \u001b[39m.\u001b[39;49mmean(axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m label \u001b[39min\u001b[39;49;00m unique_labels]))\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/numpy/core/shape_base.py:296\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    295\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[0;32m--> 296\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, casting\u001b[39m=\u001b[39;49mcasting)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "model = Top2Vec(documents = files, speed = \"learn\", workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sizes, topic_nums = model.get_topic_sizes()\n",
    "print(topic_nums)\n",
    "\n",
    "topic_words, word_scores, topic_nums = model.get_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for words, scores, num in zip(topic_words, word_scores, topic_nums):\n",
    "    print(f\"Topic #{num}: words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
